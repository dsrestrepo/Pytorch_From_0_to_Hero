{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2aa320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrestrepo/opt/anaconda3/envs/SeguridadAlimentaria_GPU/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([299])) that is different to the input size (torch.Size([299, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/davidrestrepo/opt/anaconda3/envs/SeguridadAlimentaria_GPU/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([505])) that is different to the input size (torch.Size([505, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1.1902131823201973\n",
      "199 1.0363915922741096\n",
      "299 0.9083106455703577\n",
      "399 0.8032168609400591\n",
      "499 0.7185712717473507\n",
      "599 0.652011459072431\n",
      "699 0.6012869675954183\n",
      "799 0.5641806162893772\n",
      "899 0.5384818178912004\n",
      "999 0.5220618955790997\n",
      "1099 0.5129969902336597\n",
      "1199 0.5096746683120728\n",
      "1299 0.5107582546770573\n",
      "1399 0.5151495163639387\n",
      "1499 0.5219799801707268\n",
      "1599 0.5305696427822113\n",
      "1699 0.5403936468064785\n",
      "1799 0.5510572964946429\n",
      "1899 0.5622733905911446\n",
      "1999 0.5738391255338987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=3, out_features=60, bias=True),\n",
       " Linear(in_features=60, out_features=1, bias=True)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# https://pytorch.org/docs/stable/nn.functional.html\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, inputs, hidden, outputs):\n",
    "        \n",
    "        # Call constructor of parent class\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.hidden = hidden\n",
    "        self.outputs = outputs\n",
    "        \n",
    "        # Layers: https://pytorch.org/docs/stable/nn.html\n",
    "        self.fc1 = torch.nn.Linear(inputs, hidden)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(hidden, outputs)\n",
    "        \n",
    "    # Logic for forward pass\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Dataset\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = Model(3, 60, 1)\n",
    "epoch = 2000\n",
    "batch_size = 299\n",
    "#batches = int(len(x)/batch_size)\n",
    "batches = len(x) // batch_size\n",
    "\n",
    "# Loss functions: \n",
    "#criterion = torch.nn.MSELoss(reduction='sum')\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizers: https://pytorch.org/docs/stable/optim.html\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "for t in range(2000):\n",
    "    \n",
    "    # Batch\n",
    "    loss_batch = []\n",
    "    \n",
    "    for b in range(batches):\n",
    "        # Just in the last batch\n",
    "        if b == batches-1:\n",
    "            x_b = xx[b*batch_size:]\n",
    "            y_b = y[b*batch_size:]\n",
    "        else:\n",
    "            x_b = xx[b*batch_size:(b+1)*batch_size]\n",
    "            y_b = y[b*batch_size:(b+1)*batch_size]\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_b)\n",
    "\n",
    "        #y_pred = torch.flatten(y_pred, start_dim=0) # if I use reduction\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y_b)\n",
    "        \n",
    "        loss_batch.append(loss.item())\n",
    "          \n",
    "    if t % 100 == 99:\n",
    "        print(t, np.mean(loss_batch))\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75964f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
